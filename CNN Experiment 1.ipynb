{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FTG0v_YeFPvW",
        "outputId": "d366d545-0550-40f0-d9b7-0f629b5b19eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "TensorFlow version: 2.18.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Memory growth set to True\n",
            "=== Training on CIFAR-10 ===\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n",
            "Training data range: 0.0 to 1.0\n",
            "Validation data range: 0.0 to 1.0\n",
            "Test data range: 0.0 to 1.0\n",
            "Dataset: cifar10\n",
            "Training set shape: (45000, 32, 32, 3), (45000, 10)\n",
            "Validation set shape: (5000, 32, 32, 3), (5000, 10)\n",
            "Test set shape: (10000, 32, 32, 3), (10000, 10)\n",
            "Building a new model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cifar_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cifar_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_pool (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn_dense (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu_dense (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_dense (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m362,026\u001b[0m (1.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,026</span> (1.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m360,106\u001b[0m (1.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">360,106</span> (1.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer names in the model:\n",
            "0: input_layer\n",
            "1: conv1_1\n",
            "2: bn1_1\n",
            "3: relu1_1\n",
            "4: conv1_2\n",
            "5: bn1_2\n",
            "6: relu1_2\n",
            "7: pool1\n",
            "8: dropout1\n",
            "9: conv2_1\n",
            "10: bn2_1\n",
            "11: relu2_1\n",
            "12: conv2_2\n",
            "13: bn2_2\n",
            "14: relu2_2\n",
            "15: pool2\n",
            "16: dropout2\n",
            "17: conv3_1\n",
            "18: bn3_1\n",
            "19: relu3_1\n",
            "20: conv3_2\n",
            "21: bn3_2\n",
            "22: relu3_2\n",
            "23: pool3\n",
            "24: dropout3\n",
            "25: global_pool\n",
            "26: dense1\n",
            "27: bn_dense\n",
            "28: relu_dense\n",
            "29: dropout_dense\n",
            "30: output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3036 - loss: 1.9992\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15960, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 112ms/step - accuracy: 0.3038 - loss: 1.9985 - val_accuracy: 0.1596 - val_loss: 3.8004 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4375 - loss: 1.5308"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.15960\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.5308 - val_accuracy: 0.1588 - val_loss: 3.7884 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5006 - loss: 1.3821\n",
            "Epoch 3: val_accuracy improved from 0.15960 to 0.46820, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.5006 - loss: 1.3819 - val_accuracy: 0.4682 - val_loss: 1.7348 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6484 - loss: 1.1347\n",
            "Epoch 4: val_accuracy did not improve from 0.46820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6484 - loss: 1.1347 - val_accuracy: 0.4542 - val_loss: 1.7514 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5872 - loss: 1.1623\n",
            "Epoch 5: val_accuracy did not improve from 0.46820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.5872 - loss: 1.1622 - val_accuracy: 0.4202 - val_loss: 2.3515 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6016 - loss: 1.1150\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.46820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 1.1150 - val_accuracy: 0.4464 - val_loss: 2.0209 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6356 - loss: 1.0270\n",
            "Epoch 7: val_accuracy improved from 0.46820 to 0.59860, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6356 - loss: 1.0269 - val_accuracy: 0.5986 - val_loss: 1.1643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 0.8954\n",
            "Epoch 8: val_accuracy improved from 0.59860 to 0.59960, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.8954 - val_accuracy: 0.5996 - val_loss: 1.1563 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6602 - loss: 0.9535\n",
            "Epoch 9: val_accuracy improved from 0.59960 to 0.61340, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6602 - loss: 0.9535 - val_accuracy: 0.6134 - val_loss: 1.1413 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6641 - loss: 0.8798\n",
            "Epoch 10: val_accuracy improved from 0.61340 to 0.61520, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.8798 - val_accuracy: 0.6152 - val_loss: 1.1374 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6704 - loss: 0.9294\n",
            "Epoch 11: val_accuracy improved from 0.61520 to 0.65300, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6704 - loss: 0.9293 - val_accuracy: 0.6530 - val_loss: 1.0431 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6641 - loss: 0.8496\n",
            "Epoch 12: val_accuracy did not improve from 0.65300\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.8496 - val_accuracy: 0.6490 - val_loss: 1.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6956 - loss: 0.8702\n",
            "Epoch 13: val_accuracy improved from 0.65300 to 0.66220, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.6956 - loss: 0.8702 - val_accuracy: 0.6622 - val_loss: 1.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 0.8956\n",
            "Epoch 14: val_accuracy improved from 0.66220 to 0.66340, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.8956 - val_accuracy: 0.6634 - val_loss: 1.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7022 - loss: 0.8455\n",
            "Epoch 15: val_accuracy did not improve from 0.66340\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7022 - loss: 0.8455 - val_accuracy: 0.6632 - val_loss: 1.0335 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7344 - loss: 0.7098\n",
            "Epoch 16: val_accuracy improved from 0.66340 to 0.67640, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.7098 - val_accuracy: 0.6764 - val_loss: 0.9907 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7130 - loss: 0.8170\n",
            "Epoch 17: val_accuracy improved from 0.67640 to 0.71520, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7130 - loss: 0.8170 - val_accuracy: 0.7152 - val_loss: 0.8560 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7422 - loss: 0.7113\n",
            "Epoch 18: val_accuracy improved from 0.71520 to 0.71620, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.7113 - val_accuracy: 0.7162 - val_loss: 0.8554 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7216 - loss: 0.7922\n",
            "Epoch 19: val_accuracy improved from 0.71620 to 0.74160, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7216 - loss: 0.7922 - val_accuracy: 0.7416 - val_loss: 0.7397 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7500 - loss: 0.7205\n",
            "Epoch 20: val_accuracy did not improve from 0.74160\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.7205 - val_accuracy: 0.7370 - val_loss: 0.7490 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7304 - loss: 0.7637\n",
            "Epoch 21: val_accuracy did not improve from 0.74160\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7304 - loss: 0.7637 - val_accuracy: 0.7036 - val_loss: 0.9320 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7734 - loss: 0.6545\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.74160\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.6545 - val_accuracy: 0.7030 - val_loss: 0.9440 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7467 - loss: 0.7250\n",
            "Epoch 23: val_accuracy improved from 0.74160 to 0.74680, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7467 - loss: 0.7250 - val_accuracy: 0.7468 - val_loss: 0.7403 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7969 - loss: 0.6748\n",
            "Epoch 24: val_accuracy did not improve from 0.74680\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.6748 - val_accuracy: 0.7426 - val_loss: 0.7459 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7550 - loss: 0.6995\n",
            "Epoch 25: val_accuracy improved from 0.74680 to 0.75820, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7550 - loss: 0.6995 - val_accuracy: 0.7582 - val_loss: 0.7315 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.6557\n",
            "Epoch 26: val_accuracy did not improve from 0.75820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.6557 - val_accuracy: 0.7580 - val_loss: 0.7264 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7571 - loss: 0.6886\n",
            "Epoch 27: val_accuracy did not improve from 0.75820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.7571 - loss: 0.6886 - val_accuracy: 0.7222 - val_loss: 0.8801 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7188 - loss: 0.6910\n",
            "Epoch 28: val_accuracy did not improve from 0.75820\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.6910 - val_accuracy: 0.7186 - val_loss: 0.8866 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7657 - loss: 0.6746\n",
            "Epoch 29: val_accuracy improved from 0.75820 to 0.79140, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.7657 - loss: 0.6746 - val_accuracy: 0.7914 - val_loss: 0.6145 - learning_rate: 2.5000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7578 - loss: 0.6360\n",
            "Epoch 30: val_accuracy did not improve from 0.79140\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.6360 - val_accuracy: 0.7914 - val_loss: 0.6174 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "Training completed in 6.93 minutes\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7750 - loss: 0.6473\n",
            "Test accuracy: 0.7776\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.80      0.80      0.80      1000\n",
            "  automobile       0.80      0.95      0.86      1000\n",
            "        bird       0.76      0.65      0.70      1000\n",
            "         cat       0.67      0.61      0.64      1000\n",
            "        deer       0.83      0.69      0.75      1000\n",
            "         dog       0.78      0.66      0.71      1000\n",
            "        frog       0.67      0.92      0.78      1000\n",
            "       horse       0.87      0.79      0.82      1000\n",
            "        ship       0.95      0.79      0.86      1000\n",
            "       truck       0.75      0.92      0.82      1000\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.79      0.78      0.78     10000\n",
            "weighted avg       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Generating visualizations for image 1/5, class: airplane\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 2/5, class: airplane\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 3/5, class: airplane\n",
            "Generating feature maps for layer: conv2_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 316 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a178dcfda80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 4/5, class: automobile\n",
            "Generating feature maps for layer: conv2_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 317 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a178dcd5760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 5/5, class: horse\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "Saving model summary to text file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary saved to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/model_summary_cifar10.txt\n",
            "\n",
            "Test Set Performance Summary:\n",
            "Accuracy: 0.7776\n",
            "Precision (macro): 0.7856\n",
            "Recall (macro): 0.7776\n",
            "F1 Score (macro): 0.7753\n",
            "\n",
            "=== Fine-tuning on CIFAR-100 ===\n",
            "Using best model from /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras for fine-tuning\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n",
            "Training data range: 0.0 to 1.0\n",
            "Validation data range: 0.0 to 1.0\n",
            "Test data range: 0.0 to 1.0\n",
            "Dataset: cifar100\n",
            "Training set shape: (45000, 32, 32, 3), (45000, 100)\n",
            "Validation set shape: (5000, 32, 32, 3), (5000, 100)\n",
            "Test set shape: (10000, 32, 32, 3), (10000, 100)\n",
            "Loading model from /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar10.keras for fine-tuning\n",
            "Transferred weights for layer: conv1_1\n",
            "Transferred weights for layer: bn1_1\n",
            "Transferred weights for layer: conv1_2\n",
            "Transferred weights for layer: bn1_2\n",
            "Transferred weights for layer: conv2_1\n",
            "Transferred weights for layer: bn2_1\n",
            "Transferred weights for layer: conv2_2\n",
            "Transferred weights for layer: bn2_2\n",
            "Transferred weights for layer: conv3_1\n",
            "Transferred weights for layer: bn3_1\n",
            "Transferred weights for layer: conv3_2\n",
            "Transferred weights for layer: bn3_2\n",
            "Transferred weights for layer: dense1\n",
            "Transferred weights for layer: bn_dense\n",
            "Successfully created fine-tuned model with transferred weights\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cifar_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cifar_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_1 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_2 (\u001b[38;5;33mActivation\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout3 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_pool (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn_dense (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu_dense (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_dense (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m51,300\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bn_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ relu_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m408,196\u001b[0m (1.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">408,196</span> (1.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m406,276\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,276</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer names in the model:\n",
            "0: input_layer_1\n",
            "1: conv1_1\n",
            "2: bn1_1\n",
            "3: relu1_1\n",
            "4: conv1_2\n",
            "5: bn1_2\n",
            "6: relu1_2\n",
            "7: pool1\n",
            "8: dropout1\n",
            "9: conv2_1\n",
            "10: bn2_1\n",
            "11: relu2_1\n",
            "12: conv2_2\n",
            "13: bn2_2\n",
            "14: relu2_2\n",
            "15: pool2\n",
            "16: dropout2\n",
            "17: conv3_1\n",
            "18: bn3_1\n",
            "19: relu3_1\n",
            "20: conv3_2\n",
            "21: bn3_2\n",
            "22: relu3_2\n",
            "23: pool3\n",
            "24: dropout3\n",
            "25: global_pool\n",
            "26: dense1\n",
            "27: bn_dense\n",
            "28: relu_dense\n",
            "29: dropout_dense\n",
            "30: output\n",
            "Epoch 1/35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1057 - loss: 3.9478\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24200, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 101ms/step - accuracy: 0.1059 - loss: 3.9465 - val_accuracy: 0.2420 - val_loss: 3.0154 - learning_rate: 0.0010\n",
            "Epoch 2/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.2734 - loss: 3.0157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.24200 to 0.24300, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2734 - loss: 3.0157 - val_accuracy: 0.2430 - val_loss: 3.0266 - learning_rate: 0.0010\n",
            "Epoch 3/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2509 - loss: 2.9196\n",
            "Epoch 3: val_accuracy did not improve from 0.24300\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.2509 - loss: 2.9194 - val_accuracy: 0.2392 - val_loss: 3.2893 - learning_rate: 0.0010\n",
            "Epoch 4/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3125 - loss: 2.5963\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.24300\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 2.5963 - val_accuracy: 0.2380 - val_loss: 3.2727 - learning_rate: 0.0010\n",
            "Epoch 5/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3111 - loss: 2.6064\n",
            "Epoch 5: val_accuracy improved from 0.24300 to 0.35980, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.3111 - loss: 2.6064 - val_accuracy: 0.3598 - val_loss: 2.4148 - learning_rate: 5.0000e-04\n",
            "Epoch 6/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 2.3644\n",
            "Epoch 6: val_accuracy did not improve from 0.35980\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 2.3644 - val_accuracy: 0.3556 - val_loss: 2.4439 - learning_rate: 5.0000e-04\n",
            "Epoch 7/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3403 - loss: 2.4923\n",
            "Epoch 7: val_accuracy did not improve from 0.35980\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.3404 - loss: 2.4923 - val_accuracy: 0.3322 - val_loss: 2.6490 - learning_rate: 5.0000e-04\n",
            "Epoch 8/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3125 - loss: 2.6564\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.35980\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3125 - loss: 2.6564 - val_accuracy: 0.3454 - val_loss: 2.5464 - learning_rate: 5.0000e-04\n",
            "Epoch 9/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3627 - loss: 2.3833\n",
            "Epoch 9: val_accuracy improved from 0.35980 to 0.43020, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.3627 - loss: 2.3832 - val_accuracy: 0.4302 - val_loss: 2.1578 - learning_rate: 2.5000e-04\n",
            "Epoch 10/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3906 - loss: 2.4263\n",
            "Epoch 10: val_accuracy did not improve from 0.43020\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3906 - loss: 2.4263 - val_accuracy: 0.4302 - val_loss: 2.1535 - learning_rate: 2.5000e-04\n",
            "Epoch 11/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3762 - loss: 2.3173\n",
            "Epoch 11: val_accuracy did not improve from 0.43020\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.3762 - loss: 2.3173 - val_accuracy: 0.3892 - val_loss: 2.3178 - learning_rate: 2.5000e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3984 - loss: 2.2060\n",
            "Epoch 12: val_accuracy did not improve from 0.43020\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3984 - loss: 2.2060 - val_accuracy: 0.3890 - val_loss: 2.3299 - learning_rate: 2.5000e-04\n",
            "Epoch 13/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3849 - loss: 2.2824\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.43020\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.3849 - loss: 2.2824 - val_accuracy: 0.4146 - val_loss: 2.2327 - learning_rate: 2.5000e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3516 - loss: 2.4746\n",
            "Epoch 14: val_accuracy did not improve from 0.43020\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3516 - loss: 2.4746 - val_accuracy: 0.4160 - val_loss: 2.2335 - learning_rate: 1.2500e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3997 - loss: 2.2190\n",
            "Epoch 15: val_accuracy improved from 0.43020 to 0.43340, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.3998 - loss: 2.2190 - val_accuracy: 0.4334 - val_loss: 2.1428 - learning_rate: 1.2500e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4297 - loss: 2.2705\n",
            "Epoch 16: val_accuracy improved from 0.43340 to 0.43360, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4297 - loss: 2.2705 - val_accuracy: 0.4336 - val_loss: 2.1423 - learning_rate: 1.2500e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4047 - loss: 2.2081\n",
            "Epoch 17: val_accuracy did not improve from 0.43360\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4047 - loss: 2.2081 - val_accuracy: 0.4168 - val_loss: 2.2538 - learning_rate: 1.2500e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4531 - loss: 2.1111\n",
            "Epoch 18: val_accuracy did not improve from 0.43360\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4531 - loss: 2.1111 - val_accuracy: 0.4170 - val_loss: 2.2526 - learning_rate: 1.2500e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4094 - loss: 2.1817\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.43360\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4094 - loss: 2.1817 - val_accuracy: 0.4302 - val_loss: 2.1607 - learning_rate: 1.2500e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4141 - loss: 2.3840\n",
            "Epoch 20: val_accuracy did not improve from 0.43360\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4141 - loss: 2.3840 - val_accuracy: 0.4316 - val_loss: 2.1599 - learning_rate: 6.2500e-05\n",
            "Epoch 21/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4135 - loss: 2.1746\n",
            "Epoch 21: val_accuracy improved from 0.43360 to 0.45100, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4135 - loss: 2.1745 - val_accuracy: 0.4510 - val_loss: 2.0832 - learning_rate: 6.2500e-05\n",
            "Epoch 22/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 2.4298\n",
            "Epoch 22: val_accuracy improved from 0.45100 to 0.45120, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3750 - loss: 2.4298 - val_accuracy: 0.4512 - val_loss: 2.0833 - learning_rate: 6.2500e-05\n",
            "Epoch 23/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4150 - loss: 2.1401\n",
            "Epoch 23: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.4150 - loss: 2.1401 - val_accuracy: 0.4358 - val_loss: 2.1831 - learning_rate: 6.2500e-05\n",
            "Epoch 24/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4453 - loss: 2.0785\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4453 - loss: 2.0785 - val_accuracy: 0.4340 - val_loss: 2.1893 - learning_rate: 6.2500e-05\n",
            "Epoch 25/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4173 - loss: 2.1425\n",
            "Epoch 25: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4173 - loss: 2.1425 - val_accuracy: 0.4400 - val_loss: 2.1421 - learning_rate: 3.1250e-05\n",
            "Epoch 26/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4141 - loss: 2.0605\n",
            "Epoch 26: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4141 - loss: 2.0605 - val_accuracy: 0.4400 - val_loss: 2.1397 - learning_rate: 3.1250e-05\n",
            "Epoch 27/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4229 - loss: 2.1280\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4229 - loss: 2.1280 - val_accuracy: 0.4432 - val_loss: 2.1338 - learning_rate: 3.1250e-05\n",
            "Epoch 28/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3906 - loss: 2.1822\n",
            "Epoch 28: val_accuracy did not improve from 0.45120\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3906 - loss: 2.1822 - val_accuracy: 0.4432 - val_loss: 2.1337 - learning_rate: 1.5625e-05\n",
            "Epoch 29/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4248 - loss: 2.1309\n",
            "Epoch 29: val_accuracy improved from 0.45120 to 0.45300, saving model to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/best_model_cifar100.keras\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.4248 - loss: 2.1309 - val_accuracy: 0.4530 - val_loss: 2.0917 - learning_rate: 1.5625e-05\n",
            "Epoch 30/35\n",
            "\u001b[1m  1/351\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4141 - loss: 2.1613\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.45300\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4141 - loss: 2.1613 - val_accuracy: 0.4528 - val_loss: 2.0913 - learning_rate: 1.5625e-05\n",
            "Epoch 31/35\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4257 - loss: 2.1252\n",
            "Epoch 31: val_accuracy did not improve from 0.45300\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.4257 - loss: 2.1252 - val_accuracy: 0.4482 - val_loss: 2.1042 - learning_rate: 7.8125e-06\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "Training completed in 7.39 minutes\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4509 - loss: 2.0294\n",
            "Test accuracy: 0.4508\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    mountain       0.79      0.72      0.75       100\n",
            "      forest       0.81      0.52      0.63       100\n",
            "        seal       1.00      0.07      0.13       100\n",
            "    mushroom       0.72      0.36      0.48       100\n",
            "         sea       0.79      0.57      0.66       100\n",
            "       tulip       0.77      0.30      0.43       100\n",
            "       camel       0.91      0.32      0.47       100\n",
            "   butterfly       0.76      0.28      0.41       100\n",
            "       cloud       0.90      0.63      0.74       100\n",
            "       apple       0.95      0.71      0.81       100\n",
            "       skunk       0.98      0.57      0.72       100\n",
            "   streetcar       0.94      0.78      0.85       100\n",
            "      rocket       0.94      0.61      0.74       100\n",
            "        lamp       0.86      0.19      0.31       100\n",
            "        lion       0.70      0.38      0.49       100\n",
            "        wolf       0.97      0.34      0.50       100\n",
            "        rose       0.68      0.69      0.68       100\n",
            "      orange       0.90      0.83      0.86       100\n",
            "    dinosaur       0.89      0.31      0.46       100\n",
            "  chimpanzee       0.86      0.65      0.74       100\n",
            "\n",
            "   micro avg       0.85      0.49      0.62      2000\n",
            "   macro avg       0.86      0.49      0.59      2000\n",
            "weighted avg       0.86      0.49      0.59      2000\n",
            "\n",
            "\n",
            "Generating visualizations for image 1/5, class: willow_tree\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 2/5, class: tulip\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 3/5, class: chair\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 4/5, class: dolphin\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "\n",
            "Generating visualizations for image 5/5, class: sea\n",
            "Generating feature maps for layer: conv2_2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
            "Generating Grad-CAM with auto-selected layer\n",
            "Automatically selected layer: conv3_2 for Grad-CAM\n",
            "Saving model summary to text file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary saved to /content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)/model_summary_cifar100.txt\n",
            "\n",
            "Test Set Performance Summary:\n",
            "Accuracy: 0.4508\n",
            "Precision (macro): 0.4786\n",
            "Recall (macro): 0.4508\n",
            "F1 Score (macro): 0.4403\n",
            "Training and evaluation completed!\n"
          ]
        }
      ],
      "source": [
        "# CNN Implementation for CIFAR Datasets with 3 convulational blocks\n",
        "\n",
        "!pip install -q tensorflow matplotlib seaborn scikit-learn opencv-python\n",
        "\n",
        "# Mounting Google Drive for saving models and results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a directory to save models and results\n",
        "import os\n",
        "save_dir = '/content/drive/MyDrive/CIFAR_CNN_Project (3 blocks)'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Checking GPU availability\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Set memory growth to avoid OOM errors\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "    print(\"Memory growth set to True\")\n",
        "\n",
        "# Import all required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.datasets import cifar10, cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Function to load and preprocess CIFAR datasets\n",
        "def load_and_preprocess_data(dataset='cifar10', validation_split=0.1):\n",
        "\n",
        "    # Load the dataset\n",
        "    if dataset == 'cifar10':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        num_classes = 10\n",
        "    else:  # cifar100\n",
        "        (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "        num_classes = 100\n",
        "\n",
        "    # Create a validation set\n",
        "    val_size = int(len(x_train) * validation_split)\n",
        "    indices = np.random.permutation(len(x_train))\n",
        "    train_indices, val_indices = indices[val_size:], indices[:val_size]\n",
        "\n",
        "    x_val, y_val = x_train[val_indices], y_train[val_indices]\n",
        "    x_train, y_train = x_train[train_indices], y_train[train_indices]\n",
        "\n",
        "    # Convert data to float32 and normalize\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_val = x_val.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Print data ranges to verify normalization\n",
        "    print(f\"Training data range: {x_train.min()} to {x_train.max()}\")\n",
        "    print(f\"Validation data range: {x_val.min()} to {x_val.max()}\")\n",
        "    print(f\"Test data range: {x_test.min()} to {x_test.max()}\")\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_val = to_categorical(y_val, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(f'Dataset: {dataset}')\n",
        "    print(f'Training set shape: {x_train.shape}, {y_train.shape}')\n",
        "    print(f'Validation set shape: {x_val.shape}, {y_val.shape}')\n",
        "    print(f'Test set shape: {x_test.shape}, {y_test.shape}')\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test, num_classes\n",
        "\n",
        "# Create a data augmentation generator\n",
        "def create_data_generator():\n",
        "\n",
        "    return ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.1,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "# Build a simpler and more stable CNN model\n",
        "def build_model(input_shape, num_classes):\n",
        "\n",
        "    # Use functional API instead of Sequential for better visualization support\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional block\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', name='conv1_1')(inputs)\n",
        "    x = layers.BatchNormalization(name='bn1_1')(x)\n",
        "    x = layers.Activation('relu', name='relu1_1')(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', name='conv1_2')(x)\n",
        "    x = layers.BatchNormalization(name='bn1_2')(x)\n",
        "    x = layers.Activation('relu', name='relu1_2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
        "    x = layers.Dropout(0.2, name='dropout1')(x)\n",
        "\n",
        "    # Second convolutional block\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', name='conv2_1')(x)\n",
        "    x = layers.BatchNormalization(name='bn2_1')(x)\n",
        "    x = layers.Activation('relu', name='relu2_1')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', name='conv2_2')(x)\n",
        "    x = layers.BatchNormalization(name='bn2_2')(x)\n",
        "    x = layers.Activation('relu', name='relu2_2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
        "    x = layers.Dropout(0.3, name='dropout2')(x)\n",
        "\n",
        "    # Third convolutional block\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', name='conv3_1')(x)\n",
        "    x = layers.BatchNormalization(name='bn3_1')(x)\n",
        "    x = layers.Activation('relu', name='relu3_1')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', name='conv3_2')(x)\n",
        "    x = layers.BatchNormalization(name='bn3_2')(x)\n",
        "    x = layers.Activation('relu', name='relu3_2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name='pool3')(x)\n",
        "    x = layers.Dropout(0.4, name='dropout3')(x)\n",
        "\n",
        "    # Classification layers\n",
        "    x = layers.GlobalAveragePooling2D(name='global_pool')(x)\n",
        "    x = layers.Dense(512, name='dense1')(x)\n",
        "    x = layers.BatchNormalization(name='bn_dense')(x)\n",
        "    x = layers.Activation('relu', name='relu_dense')(x)\n",
        "    x = layers.Dropout(0.5, name='dropout_dense')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name='cifar_cnn')\n",
        "    return model\n",
        "\n",
        "# visualization functions\n",
        "def visualize_feature_maps(model, image, layer_name):\n",
        "\n",
        "    try:\n",
        "        layer = None\n",
        "        for l in model.layers:\n",
        "            if l.name == layer_name:\n",
        "                layer = l\n",
        "                break\n",
        "\n",
        "        if layer is None:\n",
        "            print(f\"Layer {layer_name} not found. Available layers:\")\n",
        "            for i, l in enumerate(model.layers):\n",
        "                print(f\"{i}: {l.name}\")\n",
        "            return None\n",
        "\n",
        "        feature_model = models.Model(\n",
        "            inputs=model.input,\n",
        "            outputs=layer.output\n",
        "        )\n",
        "\n",
        "        # Get the feature maps for the input image\n",
        "        image_batch = np.expand_dims(image, axis=0)\n",
        "        feature_maps = feature_model.predict(image_batch)\n",
        "\n",
        "        # Plot the feature maps\n",
        "        fig, axes = plt.subplots(4, 8, figsize=(15, 8))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        # Display up to 32 feature maps (or fewer if there are less)\n",
        "        num_maps = min(32, feature_maps.shape[-1])\n",
        "\n",
        "        for i in range(num_maps):\n",
        "            axes[i].imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
        "            axes[i].set_title(f'Filter {i}')\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        # Hide any unused subplots\n",
        "        for i in range(num_maps, len(axes)):\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.suptitle(f'Feature Maps from Layer: {layer_name}')\n",
        "        plt.subplots_adjust(top=0.9)\n",
        "        return plt.gcf()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in visualize_feature_maps: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Fixed grad_cam function\n",
        "def grad_cam(model, image, class_idx, layer_name=None):\n",
        "\n",
        "    try:\n",
        "        # If layer_name is not provided, find the last convolutional layer\n",
        "        if layer_name is None:\n",
        "            for layer in reversed(model.layers):\n",
        "                if isinstance(layer, layers.Conv2D):\n",
        "                    layer_name = layer.name\n",
        "                    print(f\"Automatically selected layer: {layer_name} for Grad-CAM\")\n",
        "                    break\n",
        "            else:  # No convolutional layers found\n",
        "                print(\"No convolutional layers found in the model. Cannot create Grad-CAM.\")\n",
        "                return None\n",
        "\n",
        "        # Find the layer\n",
        "        target_layer = None\n",
        "        for layer in model.layers:\n",
        "            if layer.name == layer_name:\n",
        "                target_layer = layer\n",
        "                break\n",
        "\n",
        "        if target_layer is None:\n",
        "            print(f\"Layer {layer_name} not found. Available layers:\")\n",
        "            for i, layer in enumerate(model.layers):\n",
        "                print(f\"{i}: {layer.name}\")\n",
        "            return None\n",
        "\n",
        "        # Create a model that maps the input image to the activations and output\n",
        "        grad_model = models.Model(\n",
        "            inputs=model.input,\n",
        "            outputs=[target_layer.output, model.output]\n",
        "        )\n",
        "\n",
        "        # Compute the gradient of the class output with respect to the feature maps\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Prepare the input image\n",
        "            input_image = np.expand_dims(image, axis=0)\n",
        "            input_image = tf.cast(input_image, tf.float32)\n",
        "            tape.watch(input_image)\n",
        "\n",
        "            # Get the model's output and feature maps\n",
        "            conv_outputs, predictions = grad_model(input_image)\n",
        "            class_output = predictions[:, class_idx]\n",
        "\n",
        "        # Extract gradients\n",
        "        grads = tape.gradient(class_output, conv_outputs)\n",
        "\n",
        "        # Global average pooling of the gradients\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "        # Weight the channels by the pooled gradients and sum\n",
        "        conv_outputs = conv_outputs[0]\n",
        "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "\n",
        "        # Process the heatmap for visualization\n",
        "        heatmap = np.maximum(heatmap, 0) / (np.max(heatmap) or 1e-10)  # Normalize\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "\n",
        "        # Apply colormap\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert RGB image to BGR for OpenCV\n",
        "        image_bgr = (image * 255).astype(np.uint8)\n",
        "        if len(image_bgr.shape) == 3 and image_bgr.shape[2] == 3:\n",
        "            image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Overlay heatmap on original image\n",
        "        superimposed_img = cv2.addWeighted(image_bgr, 0.6, heatmap_colored, 0.4, 0)\n",
        "\n",
        "        # Convert back to RGB for matplotlib\n",
        "        superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        return superimposed_img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in grad_cam: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Function to plot training history\n",
        "def plot_training_history(history):\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "\n",
        "    y_true_classes = np.argmax(y_true, axis=1)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    if len(class_names) > 20:\n",
        "        from collections import Counter\n",
        "        most_common_classes = [cls for cls, _ in Counter(y_true_classes).most_common(10)]\n",
        "\n",
        "        mask = np.isin(y_true_classes, most_common_classes)\n",
        "        y_true_classes_filtered = y_true_classes[mask]\n",
        "        y_pred_classes_filtered = y_pred_classes[mask]\n",
        "\n",
        "        selected_class_names = [class_names[i] for i in most_common_classes]\n",
        "\n",
        "        cm = confusion_matrix(y_true_classes_filtered, y_pred_classes_filtered,\n",
        "                             labels=most_common_classes)\n",
        "    else:\n",
        "        cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "        selected_class_names = class_names\n",
        "\n",
        "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
        "                xticklabels=selected_class_names, yticklabels=selected_class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Normalized Confusion Matrix')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=45)\n",
        "    return plt.gcf()\n",
        "\n",
        "# Function to analyze misclassified images\n",
        "def analyze_misclassified(x_test, y_true, y_pred, class_names, num_images=10):\n",
        "\n",
        "    y_true_classes = np.argmax(y_true, axis=1)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    misclassified_indices = np.where(y_true_classes != y_pred_classes)[0]\n",
        "\n",
        "    if len(misclassified_indices) == 0:\n",
        "        print(\"No misclassified images found.\")\n",
        "        return None\n",
        "\n",
        "    selected_indices = np.random.choice(\n",
        "        misclassified_indices,\n",
        "        size=min(num_images, len(misclassified_indices)),\n",
        "        replace=False\n",
        "    )\n",
        "\n",
        "    num_cols = 5\n",
        "    num_rows = (len(selected_indices) + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        true_class = y_true_classes[idx]\n",
        "        pred_class = y_pred_classes[idx]\n",
        "\n",
        "        axes[i].imshow(x_test[idx])\n",
        "        axes[i].set_title(f'True: {class_names[true_class]}\\nPred: {class_names[pred_class]}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    for i in range(len(selected_indices), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Misclassified Images Analysis')\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    return fig\n",
        "\n",
        "def get_cifar100_class_names():\n",
        "\n",
        "    return [\n",
        "        'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "        'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "        'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "        'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "        'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "        'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "        'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "        'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "        'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "        'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "        'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "        'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "        'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "        'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "        'worm'\n",
        "    ]\n",
        "\n",
        "# train_model function\n",
        "def train_model(dataset='cifar10', batch_size=128, epochs=35, fine_tune=False, model_path=None):\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test, num_classes = load_and_preprocess_data(dataset)\n",
        "\n",
        "    # Get class names\n",
        "    if dataset == 'cifar10':\n",
        "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                      'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    else:  # cifar100\n",
        "        class_names = get_cifar100_class_names()\n",
        "\n",
        "    # Create data generator for augmentation\n",
        "    datagen = create_data_generator()\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Colab-specific: Create TensorBoard callback\n",
        "    tensorboard_callback = callbacks.TensorBoard(\n",
        "        log_dir=f'{save_dir}/logs/{dataset}_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
        "        histogram_freq=1\n",
        "    )\n",
        "\n",
        "    # Build or load the model\n",
        "    if fine_tune and model_path and os.path.exists(model_path):\n",
        "        print(f\"Loading model from {model_path} for fine-tuning\")\n",
        "        try:\n",
        "            # Load the base model\n",
        "            base_model = models.load_model(model_path, compile=False)\n",
        "\n",
        "            if hasattr(base_model, 'input_shape'):\n",
        "                input_shape = base_model.input_shape[1:]\n",
        "            else:\n",
        "                input_shape = x_train.shape[1:]\n",
        "\n",
        "            model = build_model(input_shape, num_classes)\n",
        "\n",
        "            for i, layer in enumerate(model.layers[:-1]):\n",
        "                if i < len(base_model.layers) and layer.name in [l.name for l in base_model.layers]:\n",
        "                    base_layer = None\n",
        "                    for bl in base_model.layers:\n",
        "                        if bl.name == layer.name:\n",
        "                            base_layer = bl\n",
        "                            break\n",
        "\n",
        "                    if base_layer and len(layer.get_weights()) > 0:\n",
        "                        # Check if shapes match\n",
        "                        base_weights = base_layer.get_weights()\n",
        "                        if all(w1.shape == w2.shape for w1, w2 in zip(layer.get_weights(), base_weights)):\n",
        "                            layer.set_weights(base_weights)\n",
        "                            print(f\"Transferred weights for layer: {layer.name}\")\n",
        "\n",
        "            print(\"Successfully created fine-tuned model with transferred weights\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or modifying pre-trained model: {str(e)}\")\n",
        "            print(\"Building a new model instead...\")\n",
        "            model = build_model(x_train.shape[1:], num_classes)\n",
        "    else:\n",
        "        print(\"Building a new model...\")\n",
        "        model = build_model(x_train.shape[1:], num_classes)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Print layer names for debugging\n",
        "    print(\"\\nLayer names in the model:\")\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        print(f\"{i}: {layer.name}\")\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks_list = [\n",
        "        callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        callbacks.ModelCheckpoint(\n",
        "            filepath=f'{save_dir}/best_model_{dataset}.keras',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tensorboard_callback\n",
        "    ]\n",
        "\n",
        "    # Train the model with data generator\n",
        "    train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "    steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Print training time\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time/60:.2f} minutes\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(x_test, verbose=1)\n",
        "\n",
        "    # Classification report\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    if dataset == 'cifar100':\n",
        "        # For CIFAR-100, show only the most common classes in the report\n",
        "        from collections import Counter\n",
        "        most_common_classes = [cls for cls, _ in Counter(y_true_classes).most_common(20)]\n",
        "        selected_class_names = [class_names[i] for i in most_common_classes]\n",
        "\n",
        "        # Filter to most common classes for report\n",
        "        mask = np.isin(y_true_classes, most_common_classes)\n",
        "        if np.any(mask):  # Make sure we have at least one sample\n",
        "            y_true_filtered = y_true_classes[mask]\n",
        "            y_pred_filtered = y_pred_classes[mask]\n",
        "\n",
        "            print(classification_report(\n",
        "                y_true_filtered,\n",
        "                y_pred_filtered,\n",
        "                labels=most_common_classes,  # Important: specify the labels\n",
        "                target_names=selected_class_names\n",
        "            ))\n",
        "        else:\n",
        "            print(\"No samples found for the selected classes.\")\n",
        "    else:\n",
        "        print(classification_report(y_true_classes, y_pred_classes,\n",
        "                                  target_names=class_names))\n",
        "\n",
        "    # Plot training history\n",
        "    history_fig = plot_training_history(history)\n",
        "    history_fig.savefig(f'{save_dir}/training_history_{dataset}.png')\n",
        "    plt.close(history_fig)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm_fig = plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "    cm_fig.savefig(f'{save_dir}/confusion_matrix_{dataset}.png')\n",
        "    plt.close(cm_fig)\n",
        "\n",
        "    # Analyze misclassified images\n",
        "    misclassified_fig = analyze_misclassified(x_test, y_test, y_pred, class_names)\n",
        "    if misclassified_fig:\n",
        "        misclassified_fig.savefig(f'{save_dir}/misclassified_{dataset}.png')\n",
        "        plt.close(misclassified_fig)\n",
        "\n",
        "    # Try/except blocks for visualizations to handle any errors gracefully\n",
        "    try:\n",
        "        # Find correctly classified images\n",
        "        correct_indices = np.where(y_true_classes == y_pred_classes)[0]\n",
        "        if len(correct_indices) > 0:\n",
        "            # Select a few random correctly classified images\n",
        "            sample_indices = np.random.choice(correct_indices, size=min(5, len(correct_indices)), replace=False)\n",
        "\n",
        "            # For each selected image, generate visualizations\n",
        "            for i, sample_idx in enumerate(sample_indices):\n",
        "                sample_image = x_test[sample_idx]\n",
        "                true_class = y_true_classes[sample_idx]\n",
        "\n",
        "                print(f\"\\nGenerating visualizations for image {i+1}/{len(sample_indices)}, \"\n",
        "                      f\"class: {class_names[true_class]}\")\n",
        "\n",
        "                try:\n",
        "                    # 1. Feature map visualization\n",
        "                    # Find a good conv layer to visualize (middle conv layer is usually good)\n",
        "                    conv_layers = [layer.name for layer in model.layers if 'conv' in layer.name.lower()]\n",
        "                    if conv_layers:\n",
        "                        # Choose a middle conv layer\n",
        "                        feature_layer = conv_layers[len(conv_layers) // 2]\n",
        "                        print(f\"Generating feature maps for layer: {feature_layer}\")\n",
        "                        feature_fig = visualize_feature_maps(model, sample_image, feature_layer)\n",
        "                        if feature_fig:\n",
        "                            feature_fig.savefig(f'{save_dir}/feature_maps_{dataset}_img{i+1}.png')\n",
        "                            plt.close(feature_fig)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error generating feature maps: {str(e)}\")\n",
        "\n",
        "                try:\n",
        "                    # 2. Grad-CAM visualization\n",
        "                    print(f\"Generating Grad-CAM with auto-selected layer\")\n",
        "                    gradcam_img = grad_cam(model, sample_image, true_class)\n",
        "\n",
        "                    if gradcam_img is not None:\n",
        "                        plt.figure(figsize=(10, 5))\n",
        "                        plt.subplot(1, 2, 1)\n",
        "                        plt.imshow(sample_image)\n",
        "                        plt.title(f'Original Image: {class_names[true_class]}')\n",
        "                        plt.axis('off')\n",
        "\n",
        "                        plt.subplot(1, 2, 2)\n",
        "                        plt.imshow(gradcam_img)\n",
        "                        plt.title('Grad-CAM Visualization')\n",
        "                        plt.axis('off')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        plt.savefig(f'{save_dir}/gradcam_{dataset}_img{i+1}.png')\n",
        "                        plt.close()\n",
        "                except Exception as e:\n",
        "                    print(f\"Error generating Grad-CAM: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during visualization: {str(e)}\")\n",
        "\n",
        "    # Save model summary to text file\n",
        "    print(\"Saving model summary to text file...\")\n",
        "    with open(f'{save_dir}/model_summary_{dataset}.txt', 'w') as f:\n",
        "        # Create a string representation of the model summary\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "    print(f\"Model summary saved to {save_dir}/model_summary_{dataset}.txt\")\n",
        "\n",
        "    # Save full training history to CSV for further analysis\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    history_df.to_csv(f'{save_dir}/training_history_{dataset}.csv', index=False)\n",
        "\n",
        "    # Calculate and report performance metrics on test set\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "    # Overall metrics\n",
        "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    # For multiclass metrics, use macro averaging to get an overall score\n",
        "    precision = precision_score(y_true_classes, y_pred_classes, average='macro')\n",
        "    recall = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
        "\n",
        "    print(\"\\nTest Set Performance Summary:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision (macro): {precision:.4f}\")\n",
        "    print(f\"Recall (macro): {recall:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1:.4f}\")\n",
        "\n",
        "    # Save performance metrics to file\n",
        "    with open(f'{save_dir}/performance_metrics_{dataset}.txt', 'w') as f:\n",
        "        f.write(f\"Dataset: {dataset}\\n\")\n",
        "        f.write(f\"Model: CNN with Batch Normalization\\n\")\n",
        "        f.write(f\"Training time: {training_time/60:.2f} minutes\\n\\n\")\n",
        "        f.write(f\"Test accuracy: {accuracy:.4f}\\n\")\n",
        "        f.write(f\"Precision (macro): {precision:.4f}\\n\")\n",
        "        f.write(f\"Recall (macro): {recall:.4f}\\n\")\n",
        "        f.write(f\"F1 Score (macro): {f1:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"Classification Report:\\n\")\n",
        "        if dataset == 'cifar100':\n",
        "            if np.any(mask):\n",
        "                report = classification_report(\n",
        "                    y_true_filtered,\n",
        "                    y_pred_filtered,\n",
        "                    labels=most_common_classes,\n",
        "                    target_names=selected_class_names,\n",
        "                    output_dict=False\n",
        "                )\n",
        "                f.write(report)\n",
        "        else:\n",
        "            report = classification_report(\n",
        "                y_true_classes,\n",
        "                y_pred_classes,\n",
        "                target_names=class_names,\n",
        "                output_dict=False\n",
        "            )\n",
        "            f.write(report)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    best_model_path = f'{save_dir}/best_model_cifar10.keras'\n",
        "\n",
        "    # First train on CIFAR-10\n",
        "    print(\"=== Training on CIFAR-10 ===\")\n",
        "    cifar10_model, _ = train_model(dataset='cifar10', epochs=30)\n",
        "\n",
        "    # Fine-tune on CIFAR-100 using the best model from CIFAR-10 training\n",
        "    print(\"\\n=== Fine-tuning on CIFAR-100 ===\")\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"Using best model from {best_model_path} for fine-tuning\")\n",
        "        cifar100_model, _ = train_model(\n",
        "            dataset='cifar100',\n",
        "            epochs=35,\n",
        "            fine_tune=True,\n",
        "            model_path=best_model_path\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Best model file {best_model_path} not found. Training CIFAR-100 from scratch.\")\n",
        "        cifar100_model, _ = train_model(dataset='cifar100', epochs=35)\n",
        "\n",
        "    print(\"Training and evaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Xz8yjcaTnU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}